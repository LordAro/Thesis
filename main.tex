\documentclass[11pt,a4paper,notitlepage]{report}
\usepackage[british]{babel} % British hyphenation patterns, etc.
\usepackage{csquotes}
\usepackage[T1]{fontenc}
\usepackage[final]{microtype}
\usepackage[a4paper]{geometry}
\usepackage{listings}
\usepackage{titling}
\usepackage[style=ieee,backend=biber]{biblatex}
\usepackage{fancyvrb} % VerbatimInput

\newenvironment{changemargin}[2]{%
\begin{list}{}{%
\setlength{\topsep}{0pt}%
\setlength{\leftmargin}{#1}%
\setlength{\rightmargin}{#2}%
\setlength{\listparindent}{\parindent}%
\setlength{\itemindent}{\parindent}%
\setlength{\parsep}{\parskip}%
}%
\item[]}{\end{list}}

\addbibresource{references.bib}

% Titlepage formatting
\pretitle{\begin{center}\Huge\bfseries}
\posttitle{\par\end{center}\vspace{0.5em}}
\preauthor{\begin{center}\Large\ttfamily}
\postauthor{\par\large\supervisor\end{center}}
\predate{\par\large\centering}
\postdate{\par\wordcount\par}


% Magic hackery to automaticly generate the word count
\immediate\write18{texcount \jobname.tex -inc -1 -sum -out=wordcount.txt}
\newcommand\wordcount{\small(\input{wordcount.txt}words, counted by
\ttfamily{texcount})}

\title{Binary Code Translation from Register to Stack based code}
\author{Charles Pigott}
\date{DRAFT \today}
\newcommand\supervisor{Supervisor: Christopher Crispin-Bailey}

\begin{document}

\maketitle

%TC:group abstract 0 0
\begin{abstract}
Transmeta are a US based company, who recently surprised the computer
architecture world by developing a chip which dynamically translates Intel
binary code into machine language instructions for another (highly optimised
RISC) CPU core. In doing so it allows Intel code to execute in real-time without
recompilation, but using a (claimed) much more power efficient processor
architecture.

This project attempts to explore something related to the above experiment,
however the focus will be on translating code into potentially parallel sections
using a technique called microthreading. Choosing a relatively simple register
machine for which complier, assembler, and simulator (or processor) are readily
available would be a sensible approach. The project will involve writing a
translator algorithm in high level code, but if time allows the translator can
be â€“recoded in low-level code, or at least optimised to be as streamlined as
possible (the speed of translation is a critical factor).
\end{abstract}

\cleardoublepage

\tableofcontents

\chapter{Introduction}
\section{Aims}
This project aims to show that by converting code written for a simple
register-based architecture or processor to a stack-based architecture,
performance improvements can be found.

\section{Limitations}
Sourcing physical processors and the toolchains capable of running on both the
register-based and stack-based architectures is difficult, as what exists
already tends to be either years out of date, with only partial support, or does
not exist on both platforms. As such, this project will seek to emulate the
architectures instead.

Since the architectures will be emulated, there are precious few advantages to
continuing to use the architecture's native binary code, so this project will
instead take in some form of the respective architecture's assembly language.

\section{Statement of Ethics}
This project does not have any ethical concerns. As Transmeta have already done
a more advanced version of this project nearly two decades ago with their Crusoe
processor, any implications of the results of this project will be unlikely to
affect any commercial businesses. The software produced by this project will be
released open-source once it is completed under a permissive licence, should
anyone else want to take the project further.

\section{Problem approach}

\chapter{Literature Review}
\section{Brief history of computer architectures}
With the exception of Babbage's Analytical Engine, probably the earliest
computer architecture formerly described is that of the EDVAC (Electronic
Discrete Variable Automatic Computer), in 1945 by John von~Neumann in his
incomplete `First Draft of a Report on the EDVAC'. In it, von~Neumann described
a computer which is subdivided into six separate parts - Central Arithmetic
(CA); Central Control (CC); Memory; Input; Output and External Memory (at the
time, this was intended to be something like punched tape). These components
were described using the human nervous sytem as an analogy, with the CA, CC \&
Memory acting as associative (linking) neurons, the Input \& Output acting as
sensory \& motor neurons respectively.
Von~Neumann also wanted to keep the computer as simple as possible, so suggested
that arithmetic operations (such as add and multiply) should not be overlapped,
and performed only one digit at a time. He also noted that external input/output
should first be placed into memory, rather than directly in/out of the CC or CA.
This approach to laying out the components of a computer stuck, and the
approximate idea is still used in modern processors today.\cite{FirstDraft}

\subsection{Register machines}
In the 1950s, logic gates and switches were largely implemented using the quite
large vacuum tubes and discrete transistors. With technology improving,
integrated circuits were invented, constructing logic components using layers of
metal and oxides on polished silicon. Initially, these were only used to
implement individual logic components for computers, replacing the diodes and
resistors used before, until in 1971, Intel released the 4004 microprocessor.
It was the first commercially available fully self contained microprocessor,
with its circuitry fabricated using the new `silicon gate' technology which is
why it was able to be designed and fabricated as one chip. It's worth noting
that Intel as a company didn't have much faith in this product, opting to
instead focus on its line of memory chips and partnering with a Japanese
electronic calculator firm, Busicom, to help finance the project. Nonetheless,
the 4004 was a huge success with 4004 being produced for 10 solid years and
taking Intel to the giant in the computing world that it is
today.\cite{Aspray1997Intel}

\subsection{Stack machines}
Using stacks as part of computation has been around almost as long as computing
itself, with Zuse's Z4 making use of them for subroutines in
1945.\cite{Speiser2000KZZ} These days stacks in computer architectures and
instruction sets are nearly exclusively limited to stack frames, to give the
ability to do context ``saving'' and ``loading'' with function calls, in favour
of register based computation. However, there is a notable exception - the Java
Virtual Machine (JVM) uses a stack-based bytecode as its underlying programming
language.\cite{Schoeberl2005Design}

Instead of having named registers to store values in as part of computations,
stack machines use a stack data structure


stack scheduling


\section{Binary Translation}
ibm binary translation

transputer

\subsection{Transmeta Crusoe}
In 2000, Transmeta published a thing which was interesting\cite{TransmetaCodeMorph}

\chapter{Problem Analysis}

\chapter{Design and Implementation}
\section{Register based architecture selection}
z80 too complex, downgraded to (subset of) dcpu-16, toy cpu created by Markus
Persson for a game
\section{Stack based architecture selection}
J5. probably.

\chapter{Testing, Results and Evaluation}
\section{Instruction count}

\chapter{Conclusions}

\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography%
\clearpage

\appendix
\chapter{DCPU-16 Specification}
\VerbatimInput[fontsize=\footnotesize]{dcpu16.txt}

\end{document}
